(window.webpackJsonp=window.webpackJsonp||[]).push([[131],{453:function(t,a,s){"use strict";s.r(a);var r=s(8),e=Object(r.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"如何设计一个高并发架构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#如何设计一个高并发架构"}},[t._v("#")]),t._v(" 如何设计一个高并发架构")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/high-concurrency-design.md",target:"_blank",rel:"noopener noreferrer"}},[t._v("原文"),a("OutboundLink")],1)]),t._v(" "),a("h2",{attrs:{id:"高并发的根源"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#高并发的根源"}},[t._v("#")]),t._v(" 高并发的根源")]),t._v(" "),a("p",[t._v("数据库请求达到每秒两三千的时候基本就要完蛋了，如果数据库瞬间承载5000以上，甚至上万的并发，那一定会宕机，因为 MySQL 根本就抵挡不了高并发。")]),t._v(" "),a("p",[t._v("但现在互联网用的人越来越多，每秒并发量几千、几万、几十万的场景都很正常。那如此高的并发量再加上复杂的业务该如何解决呢？")]),t._v(" "),a("p",[t._v("可以从一下几点解决高并发的问题：")]),t._v(" "),a("ul",[a("li",[t._v("系统拆分")]),t._v(" "),a("li",[t._v("缓存")]),t._v(" "),a("li",[t._v("MQ")]),t._v(" "),a("li",[t._v("分库分表")]),t._v(" "),a("li",[t._v("读写分离")]),t._v(" "),a("li",[t._v("ElasticSearch")])]),t._v(" "),a("p",[a("img",{attrs:{src:"https://raw.githubusercontent.com/zouquchen/Images/main/imgs/high-concurrency-system-design.png",alt:"high-concurrency-system-design"}})]),t._v(" "),a("h2",{attrs:{id:"系统拆分"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#系统拆分"}},[t._v("#")]),t._v(" 系统拆分")]),t._v(" "),a("p",[t._v("将一个系统拆分为多个子系统，用 dubbo 实现远程调用。同时，每个系统连一个数据库，这样数据库的数量从1个变成了多个，就可以抗住高并发了。")]),t._v(" "),a("h2",{attrs:{id:"缓存"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#缓存"}},[t._v("#")]),t._v(" 缓存")]),t._v(" "),a("p",[a("strong",[t._v("Redis 解决的是高并发读的问题")]),t._v("，大部分的高并发场景，都是"),a("strong",[t._v("读多写少")]),t._v("，所以可以再数据库和缓存里都写一份数据，读的大量请求就可以访问缓存，毕竟 Redis 轻轻松松单机几万的并发量。")]),t._v(" "),a("h2",{attrs:{id:"mq"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mq"}},[t._v("#")]),t._v(" MQ")]),t._v(" "),a("p",[a("strong",[t._v("MQ 解决的是高并发写的问题")]),t._v("，因为 Redis 很难担任写的任务，因为数据会过期、数据格式简单、不支持 MySQL 那种复杂的事务，所以写还是要靠 MySQL 自己来完成。但为了不能让大量请求同时访问到 MySQL，所以用 MQ 来实现排队，MySQL 就可以按它自己的能力慢慢写。MQ 单机也能扛得住几万的并发量。")]),t._v(" "),a("h2",{attrs:{id:"分库分表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#分库分表"}},[t._v("#")]),t._v(" 分库分表")]),t._v(" "),a("p",[t._v("数据库最后还是难免还是会遇到高并发的问题，那么就可以将一个数据库拆分为多个数据库，多个库就能分担压力；然后将一个表拆分为多个表，每个表的数据量报错少一点，提高 sql 语句的性能。")]),t._v(" "),a("h2",{attrs:{id:"读写分离"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#读写分离"}},[t._v("#")]),t._v(" 读写分离")]),t._v(" "),a("p",[t._v("读写分离主要也是解决"),a("strong",[t._v("读多写少")]),t._v("的情况，没必要将所有的请求都集中当一个数据库上，可以让数据库搞主从架构，主库写入，从库读取，实现读取分离。读流量太多的时候，还可以继续加更多的从库。")]),t._v(" "),a("h2",{attrs:{id:"elasticsearch"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#elasticsearch"}},[t._v("#")]),t._v(" ElasticSearch")]),t._v(" "),a("p",[t._v("ES 是分布式的，可以随便扩容，天然支持高并发。一些简单的查询、统计类的和全文搜索类的操作可以通过 ES 来承载。")])])}),[],!1,null,null,null);a.default=e.exports}}]);